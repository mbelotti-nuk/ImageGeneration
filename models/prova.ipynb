{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualizedConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)\n",
    "        # initialize weights to N(0,1)\n",
    "        self.conv.weight.data.normal_(0,1)\n",
    "        self.conv.bias.data.fill_(0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)*self.get_scale()\n",
    "        return x\n",
    "    \n",
    "    def get_scale(self):\n",
    "        size_w = self.conv.weight.size()\n",
    "        fan_in = size_w[1:].numel()\n",
    "        return np.sqrt(2/fan_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "out_ch = 512\n",
    "in_ch = 512\n",
    "k = (4,4)\n",
    "shape = (1,1)\n",
    "x = torch.randn((1,out_ch,*shape))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = EqualizedConv2d(out_ch, in_ch, k, padding=3)\n",
    "conv2 = EqualizedConv2d(in_ch, in_ch, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0006, grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.conv.weight.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "out_x = conv(x)\n",
    "print(out_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2(out_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PGGAN import PixelWiseNorm\n",
    "\n",
    "class GblockPGGAN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, first_block=False):\n",
    "        super().__init__()\n",
    "        if first_block:\n",
    "            self.block = nn.Sequential(\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=4, padding=3),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = GblockPGGAN(in_channels=512, out_channels=512, first_block=True)\n",
    "block2 = GblockPGGAN(in_channels=512, out_channels=512, first_block=False)\n",
    "block3 = GblockPGGAN(in_channels=512, out_channels=256, first_block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 4, 4])\n",
      "torch.Size([1, 512, 8, 8])\n",
      "torch.Size([1, 256, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1,512,1,1))\n",
    "print(block1(x).shape)\n",
    "print(block2(block1(x)).shape)\n",
    "print(block3(block2(block1(x))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rgb = EqualizedConv2d(256, 3, 1, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_rgb(block3(block2(block1(x)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorPGGAN(nn.Module):\n",
    "    def __init__(self, latent_dim=512, out_scale=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = 1\n",
    "        self.alpha = 1\n",
    "        self.step_alpha = 0\n",
    "\n",
    "        self.upscale_blocks = nn.ModuleList()\n",
    "        self.to_rgb = nn.ModuleList()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        # add first block to get 4x4 image\n",
    "        self.upscale_blocks.append(GblockPGGAN(in_channels=latent_dim, out_channels=latent_dim, first_block=True))\n",
    "        self.to_rgb.append( EqualizedConv2d(in_channels=latent_dim, out_channels=3, kernel_size=1, padding=0), )\n",
    "\n",
    "        start_scale = np.log2(4)\n",
    "        end_scale = np.log2(out_scale)\n",
    "\n",
    "        start_scale = int(np.log2(4))\n",
    "        end_scale   = int(np.log2(out_scale))\n",
    "\n",
    "        in_ch, out_ch = latent_dim, latent_dim\n",
    "        for i in range(start_scale+1, end_scale+1):\n",
    "            in_ch = out_ch\n",
    "            if i >= 6:\n",
    "                out_ch = in_ch//2\n",
    "            else:\n",
    "                out_ch = in_ch\n",
    "            self.upscale_blocks.append(GblockPGGAN(in_channels=in_ch, out_channels=out_ch, first_block=False))\n",
    "            self.to_rgb.append( EqualizedConv2d(in_channels=out_ch, out_channels=3, kernel_size=1, padding=0), )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # go until second last layer\n",
    "        for block in self.upscale_blocks[:self.depth-1]:\n",
    "            x = block(x)\n",
    "        # compute last layer\n",
    "        x_prev = x.clone().detach()\n",
    "        print(f\"before {x.shape}\")\n",
    "        x_rgb = self.upscale_blocks[self.depth-1](x)\n",
    "        print(f\"after {x.shape}\")\n",
    "        print(f\"are equal? {torch.equal(x,x_prev)}\")\n",
    "        x_rgb = self.to_rgb[self.depth-1](x_rgb)\n",
    "        #print(f\"last layer    x_rgb {x_rgb.shape}   {x.shape}\")\n",
    "        # smooth change\n",
    "        if self.alpha < 1 and self.depth > 1: # for the first layer cannot be applied\n",
    "            x_old_rgb = self.upsample(x)\n",
    "            x_old_rgb = self.to_rgb[self.depth-2](x_old_rgb)\n",
    "            #print(f\"x_old {x_old_rgb.shape}\")\n",
    "            \n",
    "            x_rgb = self.alpha * x_rgb + (1-self.alpha) * x_old_rgb\n",
    "        return x_rgb\n",
    "    \n",
    "    def increase_net(self, n_iterations):\n",
    "        self.step_alpha = 1/n_iterations\n",
    "        self.alpha = 1/n_iterations\n",
    "        self.depth += 1\n",
    "    \n",
    "    def step(self):\n",
    "        # increase alpha\n",
    "        self.alpha += self.step_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GeneratorPGGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "layers = list(dict(g.upscale_blocks[0].block.named_children()).values())\n",
    "print(layers[0].conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,512,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before torch.Size([1, 512, 1, 1])\n",
      "after torch.Size([1, 512, 1, 1])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 4, 4])  alpha 0.5\n",
      "before torch.Size([1, 512, 4, 4])\n",
      "after torch.Size([1, 512, 4, 4])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 8, 8])  alpha 0.5\n",
      "before torch.Size([1, 512, 8, 8])\n",
      "after torch.Size([1, 512, 8, 8])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 16, 16])  alpha 0.5\n",
      "before torch.Size([1, 512, 16, 16])\n",
      "after torch.Size([1, 512, 16, 16])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 32, 32])  alpha 0.5\n",
      "before torch.Size([1, 512, 32, 32])\n",
      "after torch.Size([1, 512, 32, 32])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 64, 64])  alpha 0.5\n",
      "before torch.Size([1, 256, 64, 64])\n",
      "after torch.Size([1, 256, 64, 64])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 128, 128])  alpha 0.5\n",
      "before torch.Size([1, 128, 128, 128])\n",
      "after torch.Size([1, 128, 128, 128])\n",
      "are equal? True\n",
      "out tensor torch.Size([1, 3, 256, 256])  alpha 0.5\n"
     ]
    }
   ],
   "source": [
    "g.depth = 1\n",
    "g.alpha = 0.5\n",
    "g.step_alpha = 0.1\n",
    "for i in range(7):\n",
    "    out_x = g(x)\n",
    "    print(f\"out tensor {out_x.shape}  alpha {g.alpha}\")\n",
    "    g.depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_rgb = nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=512, kernel_size=1), nn.LeakyReLU(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_rgb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 256 512\n",
      "7 128 512\n",
      "6 64 512\n",
      "5 32 512\n",
      "4 16 512\n",
      "3 8 512\n",
      "2 4 512\n"
     ]
    }
   ],
   "source": [
    "start_scale = int(np.log2(4))\n",
    "end_scale = int(np.log2(256))\n",
    "\n",
    "for i in reversed(range(start_scale, end_scale+1)):\n",
    "    print(i, 2**i, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 512 out 512\n",
      "in 512 out 512\n",
      "in 512 out 512\n",
      "in 256 out 512\n",
      "in 128 out 256\n",
      "in 64 out 128\n"
     ]
    }
   ],
   "source": [
    "start_scale = int(np.log2(4))\n",
    "end_scale   = int(np.log2(256))\n",
    "latent_dim = 512\n",
    "out_ch, in_ch = latent_dim, latent_dim\n",
    "for i in range(start_scale+1, end_scale+1):\n",
    "    out_ch = in_ch\n",
    "    if i >= 6:\n",
    "        in_ch = out_ch//2\n",
    "    else:\n",
    "        in_ch = out_ch\n",
    "    print(f\"in {in_ch} out {out_ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PGGAN import MinibatchStd\n",
    "\n",
    "class DblockPGGAN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, last_block=False):\n",
    "        super().__init__()\n",
    "        if last_block:\n",
    "            self.block = nn.Sequential(\n",
    "                    MinibatchStd(),\n",
    "                    EqualizedConv2d(in_channels+1, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=4, padding=0),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    nn.Sequential(nn.Flatten(), nn.Linear(out_channels, 1))\n",
    "                    )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2) # down sampling\n",
    "                    )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.block(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorPGGAN(nn.Module):\n",
    "    def __init__(self, latent_dim=512, out_scale=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = 1\n",
    "        self.alpha = 1\n",
    "        self.step_alpha = 0\n",
    "\n",
    "        self.downscale_blocks = nn.ModuleList()\n",
    "        self.from_rgb = nn.ModuleList()\n",
    "        self.downscale = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.from_rgb.append( nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=latent_dim, kernel_size=1), nn.LeakyReLU(0.2) ) )\n",
    "        # 4x4 -> 1x1\n",
    "        self.downscale_blocks.append(DblockPGGAN(in_channels=latent_dim, out_channels=1, last_block=True))\n",
    "\n",
    "        start_scale = int(np.log2(4))\n",
    "        end_scale   = int(np.log2(out_scale))\n",
    "\n",
    "        out_ch, in_ch = latent_dim, latent_dim\n",
    "        for i in range(start_scale+1, end_scale+1):\n",
    "            out_ch = in_ch\n",
    "            if i >= 6:\n",
    "                in_ch = out_ch//2\n",
    "            else:\n",
    "                in_ch = out_ch\n",
    "            self.from_rgb.append( nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=in_ch, kernel_size=1), nn.LeakyReLU(0.2) ) )\n",
    "            self.downscale_blocks.append(DblockPGGAN(in_channels=in_ch, out_channels=out_ch, last_block=False))\n",
    "\n",
    "    def forward(self,x_rgb):\n",
    "        x = self.from_rgb[self.depth-1](x_rgb)\n",
    "        #print(f\"from rgb {x.shape}\")\n",
    "        x = self.downscale_blocks[self.depth-1](x)\n",
    "        #print(f\"down 1 {x.shape}\")\n",
    "\n",
    "        if self.alpha < 1.0 and self.depth > 1:\n",
    "            x_rgb = self.downscale(x_rgb)\n",
    "            x_old = self.from_rgb[self.depth-2](x_rgb)\n",
    "            #print(f\"x {x.shape}   x old {x_old.shape}\")\n",
    "            x = self.alpha * x + (1-self.alpha) * x_old \n",
    "            self.alpha += self.step_alpha\n",
    "        i = 2\n",
    "        for block in reversed(self.downscale_blocks[:self.depth-1]):\n",
    "            x = block(x)\n",
    "            #print(f\"block {i}   {x.shape}\")\n",
    "            i += 1\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DiscriminatorPGGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariobelotti/Documents/Projects/ComputerVision/ComputerVisionApplications/models/PGGAN.py:207: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = torch.std(x, dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n",
      "out tensor torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "d.depth = 1\n",
    "for i in range(2,9):\n",
    "    img = torch.randn((1,3,2**i,2**i))\n",
    "    out_d = d(img)\n",
    "    print(f\"out tensor {out_d.shape}\")\n",
    "    d.depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.depth = 1\n",
    "x_hat = torch.randn((32, 3, 4, 4))\n",
    "x_hat.requires_grad_(True)\n",
    "y_hat = d(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.autograd.grad(\n",
    "    outputs=y_hat,\n",
    "    inputs=x_hat,\n",
    "    grad_outputs=torch.ones_like(y_hat),\n",
    "    create_graph=True,\n",
    "    retain_graph=True,\n",
    "    only_inputs = True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 4, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
