{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,10,size=(64,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiffusionModel import DiffusionUNet\n",
    "resolution = 32\n",
    "net = DiffusionUNet(in_channels=3, resolution=32, attn_resolutions=[16], ch_mult=(2,2,2), channels=64, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "x = torch.randn((B,3,resolution,resolution))\n",
    "t = torch.ones((B), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.flatten(start_dim=2).mT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.sinusoidal_embedding(x, t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x, t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiffusionModel import DownBlock, UpBlock\n",
    "\n",
    "B = 32\n",
    "x = torch.randn((B,64,64,64))\n",
    "t = torch.randn((B,256))\n",
    "\n",
    "d1 = DownBlock(64, 128)\n",
    "d2 = DownBlock(128, 256)\n",
    "d3 = DownBlock(256, 512)\n",
    "\n",
    "x_1, skips_1 = d1(x, t)\n",
    "x_2, skips_2 = d2(x_1, t)\n",
    "x_3, skips_3 = d3(x_2, t)\n",
    "\n",
    "print(x_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skips_3[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u3 = UpBlock(512*2, 256)\n",
    "u2 = UpBlock(256*2, 128)\n",
    "u1 = UpBlock(128*2, 64)\n",
    "\n",
    "\n",
    "y_3 = u3( x_3, t, skips_3 )\n",
    "y_2 = u2( y_3, t, skips_2 )\n",
    "y_1 = u1( y_2, t, skips_1 )\n",
    "print(y_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conv = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "my_conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FastGan import SLEBlock, UpSampleBlock\n",
    "\n",
    "\n",
    "upblock = UpSampleBlock(in_channels=512, out_channels=512)\n",
    "sleblock = SLEBlock(size=8, low_channels=512, high_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  torch.randn((1,512,4,4))\n",
    "up_x = upblock(x)\n",
    "print(up_x.shape)\n",
    "sle_x = sleblock(up_x, torch.randn(1,64,128,128))\n",
    "print(sle_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualizedConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)\n",
    "        # initialize weights to N(0,1)\n",
    "        self.conv.weight.data.normal_(0,1)\n",
    "        self.conv.bias.data.fill_(0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)*self.get_scale()\n",
    "        return x\n",
    "    \n",
    "    def get_scale(self):\n",
    "        size_w = self.conv.weight.size()\n",
    "        fan_in = size_w[1:].numel()\n",
    "        return np.sqrt(2/fan_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ch = 512\n",
    "in_ch = 512\n",
    "k = (4,4)\n",
    "shape = (1,1)\n",
    "x = torch.randn((1,out_ch,*shape))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = EqualizedConv2d(out_ch, in_ch, k, padding=3)\n",
    "conv2 = EqualizedConv2d(in_ch, in_ch, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.conv.weight.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_x = conv(x)\n",
    "print(out_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2(out_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PGGAN import PixelWiseNorm\n",
    "\n",
    "class GblockPGGAN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, first_block=False):\n",
    "        super().__init__()\n",
    "        if first_block:\n",
    "            self.block = nn.Sequential(\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=4, padding=3),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    PixelWiseNorm(),\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = GblockPGGAN(in_channels=512, out_channels=512, first_block=True)\n",
    "block2 = GblockPGGAN(in_channels=512, out_channels=512, first_block=False)\n",
    "block3 = GblockPGGAN(in_channels=512, out_channels=256, first_block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,512,1,1))\n",
    "print(block1(x).shape)\n",
    "print(block2(block1(x)).shape)\n",
    "print(block3(block2(block1(x))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rgb = EqualizedConv2d(256, 3, 1, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_rgb(block3(block2(block1(x)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorPGGAN(nn.Module):\n",
    "    def __init__(self, latent_dim=512, out_scale=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = 1\n",
    "        self.alpha = 1\n",
    "        self.step_alpha = 0\n",
    "\n",
    "        self.upscale_blocks = nn.ModuleList()\n",
    "        self.to_rgb = nn.ModuleList()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        # add first block to get 4x4 image\n",
    "        self.upscale_blocks.append(GblockPGGAN(in_channels=latent_dim, out_channels=latent_dim, first_block=True))\n",
    "        self.to_rgb.append( EqualizedConv2d(in_channels=latent_dim, out_channels=3, kernel_size=1, padding=0), )\n",
    "\n",
    "        start_scale = np.log2(4)\n",
    "        end_scale = np.log2(out_scale)\n",
    "\n",
    "        start_scale = int(np.log2(4))\n",
    "        end_scale   = int(np.log2(out_scale))\n",
    "\n",
    "        in_ch, out_ch = latent_dim, latent_dim\n",
    "        for i in range(start_scale+1, end_scale+1):\n",
    "            in_ch = out_ch\n",
    "            if i >= 6:\n",
    "                out_ch = in_ch//2\n",
    "            else:\n",
    "                out_ch = in_ch\n",
    "            self.upscale_blocks.append(GblockPGGAN(in_channels=in_ch, out_channels=out_ch, first_block=False))\n",
    "            self.to_rgb.append( EqualizedConv2d(in_channels=out_ch, out_channels=3, kernel_size=1, padding=0), )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # go until second last layer\n",
    "        for block in self.upscale_blocks[:self.depth-1]:\n",
    "            x = block(x)\n",
    "        # compute last layer\n",
    "        x_prev = x.clone().detach()\n",
    "        print(f\"before {x.shape}\")\n",
    "        x_rgb = self.upscale_blocks[self.depth-1](x)\n",
    "        print(f\"after {x.shape}\")\n",
    "        print(f\"are equal? {torch.equal(x,x_prev)}\")\n",
    "        x_rgb = self.to_rgb[self.depth-1](x_rgb)\n",
    "        #print(f\"last layer    x_rgb {x_rgb.shape}   {x.shape}\")\n",
    "        # smooth change\n",
    "        if self.alpha < 1 and self.depth > 1: # for the first layer cannot be applied\n",
    "            x_old_rgb = self.upsample(x)\n",
    "            x_old_rgb = self.to_rgb[self.depth-2](x_old_rgb)\n",
    "            #print(f\"x_old {x_old_rgb.shape}\")\n",
    "            \n",
    "            x_rgb = self.alpha * x_rgb + (1-self.alpha) * x_old_rgb\n",
    "        return x_rgb\n",
    "    \n",
    "    def increase_net(self, n_iterations):\n",
    "        self.step_alpha = 1/n_iterations\n",
    "        self.alpha = 1/n_iterations\n",
    "        self.depth += 1\n",
    "    \n",
    "    def step(self):\n",
    "        # increase alpha\n",
    "        self.alpha += self.step_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GeneratorPGGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(dict(g.upscale_blocks[0].block.named_children()).values())\n",
    "print(layers[0].conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,512,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.depth = 1\n",
    "g.alpha = 0.5\n",
    "g.step_alpha = 0.1\n",
    "for i in range(7):\n",
    "    out_x = g(x)\n",
    "    print(f\"out tensor {out_x.shape}  alpha {g.alpha}\")\n",
    "    g.depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_rgb = nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=512, kernel_size=1), nn.LeakyReLU(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_rgb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scale = int(np.log2(4))\n",
    "end_scale = int(np.log2(256))\n",
    "\n",
    "for i in reversed(range(start_scale, end_scale+1)):\n",
    "    print(i, 2**i, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scale = int(np.log2(4))\n",
    "end_scale   = int(np.log2(256))\n",
    "latent_dim = 512\n",
    "out_ch, in_ch = latent_dim, latent_dim\n",
    "for i in range(start_scale+1, end_scale+1):\n",
    "    out_ch = in_ch\n",
    "    if i >= 6:\n",
    "        in_ch = out_ch//2\n",
    "    else:\n",
    "        in_ch = out_ch\n",
    "    print(f\"in {in_ch} out {out_ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PGGAN import MinibatchStd\n",
    "\n",
    "class DblockPGGAN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, last_block=False):\n",
    "        super().__init__()\n",
    "        if last_block:\n",
    "            self.block = nn.Sequential(\n",
    "                    MinibatchStd(),\n",
    "                    EqualizedConv2d(in_channels+1, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=4, padding=0),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    nn.Sequential(nn.Flatten(), nn.Linear(out_channels, 1))\n",
    "                    )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                    EqualizedConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    EqualizedConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.LeakyReLU(0.2, True),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2) # down sampling\n",
    "                    )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.block(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorPGGAN(nn.Module):\n",
    "    def __init__(self, latent_dim=512, out_scale=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depth = 1\n",
    "        self.alpha = 1\n",
    "        self.step_alpha = 0\n",
    "\n",
    "        self.downscale_blocks = nn.ModuleList()\n",
    "        self.from_rgb = nn.ModuleList()\n",
    "        self.downscale = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.from_rgb.append( nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=latent_dim, kernel_size=1), nn.LeakyReLU(0.2) ) )\n",
    "        # 4x4 -> 1x1\n",
    "        self.downscale_blocks.append(DblockPGGAN(in_channels=latent_dim, out_channels=1, last_block=True))\n",
    "\n",
    "        start_scale = int(np.log2(4))\n",
    "        end_scale   = int(np.log2(out_scale))\n",
    "\n",
    "        out_ch, in_ch = latent_dim, latent_dim\n",
    "        for i in range(start_scale+1, end_scale+1):\n",
    "            out_ch = in_ch\n",
    "            if i >= 6:\n",
    "                in_ch = out_ch//2\n",
    "            else:\n",
    "                in_ch = out_ch\n",
    "            self.from_rgb.append( nn.Sequential( EqualizedConv2d(in_channels=3, out_channels=in_ch, kernel_size=1), nn.LeakyReLU(0.2) ) )\n",
    "            self.downscale_blocks.append(DblockPGGAN(in_channels=in_ch, out_channels=out_ch, last_block=False))\n",
    "\n",
    "    def forward(self,x_rgb):\n",
    "        x = self.from_rgb[self.depth-1](x_rgb)\n",
    "        #print(f\"from rgb {x.shape}\")\n",
    "        x = self.downscale_blocks[self.depth-1](x)\n",
    "        #print(f\"down 1 {x.shape}\")\n",
    "\n",
    "        if self.alpha < 1.0 and self.depth > 1:\n",
    "            x_rgb = self.downscale(x_rgb)\n",
    "            x_old = self.from_rgb[self.depth-2](x_rgb)\n",
    "            #print(f\"x {x.shape}   x old {x_old.shape}\")\n",
    "            x = self.alpha * x + (1-self.alpha) * x_old \n",
    "            self.alpha += self.step_alpha\n",
    "        i = 2\n",
    "        for block in reversed(self.downscale_blocks[:self.depth-1]):\n",
    "            x = block(x)\n",
    "            #print(f\"block {i}   {x.shape}\")\n",
    "            i += 1\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DiscriminatorPGGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.depth = 1\n",
    "for i in range(2,9):\n",
    "    img = torch.randn((1,3,2**i,2**i))\n",
    "    out_d = d(img)\n",
    "    print(f\"out tensor {out_d.shape}\")\n",
    "    d.depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.depth = 1\n",
    "x_hat = torch.randn((32, 3, 4, 4))\n",
    "x_hat.requires_grad_(True)\n",
    "y_hat = d(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.autograd.grad(\n",
    "    outputs=y_hat,\n",
    "    inputs=x_hat,\n",
    "    grad_outputs=torch.ones_like(y_hat),\n",
    "    create_graph=True,\n",
    "    retain_graph=True,\n",
    "    only_inputs = True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
