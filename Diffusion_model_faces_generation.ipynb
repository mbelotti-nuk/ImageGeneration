{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.DiffusionModel import DiffusionUNet\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_res = (16,16)\n",
    "device = \"mps\"\n",
    "learning_rate = 3E-4\n",
    "num_epochs = 70\n",
    "batch_size = 64\n",
    "in_channels = 1\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\t\t\ttransforms.Resize(out_res),\n",
    "\t\t\ttransforms.CenterCrop(out_res),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\t\t\t])\n",
    "\n",
    "#train_set = datasets.ImageFolder(\"Data/celeb\", transform=transform)\n",
    "train_set = datasets.MNIST(root=\".\", download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine diffusion schedule\n",
    "\n",
    "$$ x_t = cos( \\frac{t}{T} \\frac{\\pi}{2} ) x_0 + sin( \\frac{t}{T} \\frac{\\pi}{2} ) \\epsilon $$\n",
    "\n",
    "Where $ \\epsilon $ is a noise distributed as normal gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_diffusion_schedule(diffusion_times):\n",
    "    signal_rates = torch.cos(diffusion_times * torch.pi / 2)\n",
    "    noise_rates = torch.sin(diffusion_times * torch.pi / 2)\n",
    "    return signal_rates, noise_rates\n",
    "\n",
    "def offset_cosine_diffusion_schedule(diffusion_times):\n",
    "    min_signal_rate = torch.Tensor( [0.02] )\n",
    "    max_signal_rate = torch.Tensor( [0.95] )\n",
    "    start_angle = torch.acos(max_signal_rate)\n",
    "    end_angle = torch.acos(min_signal_rate)\n",
    "\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle-start_angle)\n",
    "    signal_rates = torch.cos(diffusion_angles)\n",
    "    noise_rates = torch.sin(diffusion_angles)\n",
    "    return signal_rates, noise_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "diffusion_times = torch.Tensor( [t/T for t in range(T)] )\n",
    "s_rates_cos, n_rates_cos = cosine_diffusion_schedule(diffusion_times)\n",
    "s_rates_off, n_rates_off = offset_cosine_diffusion_schedule(diffusion_times)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,3))\n",
    "axs[0].plot(diffusion_times, s_rates_cos, label=\"Cosine\")\n",
    "axs[0].plot(diffusion_times, s_rates_off, label=\"Offset cos\")\n",
    "axs[0].set_ylabel(\"Signal rate\")\n",
    "axs[0].set_xlabel(\"Diffusion time\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(diffusion_times, n_rates_cos, label=\"Cosine\")\n",
    "axs[1].plot(diffusion_times, n_rates_off, label=\"Offset cos\")\n",
    "axs[1].set_ylabel(\"Noise rate\")\n",
    "axs[1].set_xlabel(\"Diffusion time\")\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = train_set[0]\n",
    "\n",
    "n_samples = 10\n",
    "noises = torch.randn_like(img)\n",
    "ptr, rng = 0, int(T/n_samples)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_samples, figsize=(18,2))\n",
    "fig.suptitle(\"Cosine diffusion schedule\")\n",
    "for i in range(n_samples):\n",
    "    noise_img = s_rates_cos[ptr] * img + n_rates_cos[ptr] * noises\n",
    "    noise_img = torch.clip( noise_img, min=0, max=1 )\n",
    "    axs[i].imshow(noise_img.permute(1,2,0))\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    ptr += rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionUNet(in_channels=in_channels, resolution=out_res[0], attn_resolutions=[8], ch_mult=(1,2,2), channels=16, time_steps=T).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(imgs, schedule=offset_cosine_diffusion_schedule):\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    B = imgs.shape[0]\n",
    "\n",
    "    times = torch.randint(0, T,(batch_size,))\n",
    "    diff_times = (times/T)[:, None, None, None]\n",
    "    \n",
    "    noises = torch.randn(size=imgs.shape)\n",
    "    s_rates, n_rates = schedule(diff_times)\n",
    "    # add noise to current image\n",
    "    noisy_imgs = s_rates * imgs + n_rates * noises\n",
    "\n",
    "    pred_noises = model(noisy_imgs.to(device), (times))\n",
    "\n",
    "    loss = loss_fn(pred_noises.cpu(), noises)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    del noisy_imgs\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_noise = torch.randn(size=(n_samples,in_channels,*out_res))\n",
    "schedule = cosine_diffusion_schedule\n",
    "data_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "n_it = len(train_set)//batch_size +1\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    bar = tqdm(range(len(data_loader)))\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for i in bar:\n",
    "        imgs, _ = next(iter(data_loader))\n",
    "        loss = epoch(imgs)\n",
    "        epoch_loss += loss\n",
    "        torch.mps.synchronize()\n",
    "    epoch_loss = epoch_loss/len(data_loader)\n",
    "    print(f\"epoch {e+1:3.0f} \\t  loss {epoch_loss:4.4f}\")\n",
    "    if e%10 == 0:\n",
    "        model.eval()\n",
    "        plt.clf()\n",
    "        fig, axs = plt.subplots(1, n_samples, figsize=(18,2))\n",
    "        out_imgs, denoising = model.reverse_diffusion(gen_noise.to(device), diffusion_steps=100, schedule=schedule) \n",
    "        #model.sample_images(gen_noise.to(device), diffusion_steps=100, schedule=schedule).cpu()\n",
    "        for i in range(n_samples):\n",
    "            axs[i].imshow(out_imgs[i].permute(1,2,0))\n",
    "            axs[i].set_xticks([])\n",
    "            axs[i].set_yticks([])\n",
    "        plt.show()\n",
    "        #plt.savefig(os.path.join(check_point_dir , 'img_schedule_%i'%(n_schedule)))\n",
    "        gen_noise.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
